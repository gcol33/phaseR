% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/loo.R
\name{loo}
\alias{loo}
\title{Leave-One-Out Cross-Validation via PSIS}
\usage{
loo(object, ...)
}
\arguments{
\item{object}{A \code{phase_fit} object}

\item{...}{Additional arguments (unused)}
}
\value{
A \code{loo_phaseR} object with components:
\itemize{
\item \code{elpd_loo}: Expected log pointwise predictive density for LOO
\item \code{p_loo}: Effective number of parameters
\item \code{looic}: LOO information criterion (-2 * elpd_loo)
\item \code{se_elpd_loo}: Standard error of elpd_loo
\item \code{pointwise}: Data frame with per-observation values
\item \code{diagnostics}: List with k-hat values and convergence info
}
}
\description{
Computes approximate leave-one-out cross-validation using Pareto-smoothed
importance sampling (PSIS-LOO). This provides an estimate of out-of-sample
predictive accuracy that is more robust than WAIC.
}
\details{
PSIS-LOO approximates leave-one-out cross-validation without refitting
the model. It uses importance sampling with Pareto-smoothed weights to
estimate the predictive density for each held-out observation.

The k-hat diagnostic indicates the reliability of the estimate:
\itemize{
\item k < 0.5: Good, estimates are reliable
\item 0.5 <= k < 0.7: Okay, estimates may have some error
\item k >= 0.7: Bad, estimates are unreliable for these observations
}

If many observations have k > 0.7, consider using K-fold cross-validation
instead.
}
\examples{
\dontrun{
fit <- fit_phaseR(model, data)
loo_result <- loo(fit)
print(loo_result)

# Check diagnostics
plot(loo_result$diagnostics$pareto_k)
}

}
\references{
Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC.
Statistics and Computing 27, 1413-1432.
}
\seealso{
\code{\link[=waic]{waic()}}, \code{\link[=loo_compare]{loo_compare()}}
}
